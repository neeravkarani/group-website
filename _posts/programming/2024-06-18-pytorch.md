---
layout: post
title: "PyTorch Basics"
---

## Introduction
PyTorch leverages CUDA (a parallel computing platform developed by NVIDIA for general computing on GPUs) to enable you to run machine learning code on GPUs.

## Tensors
Tensors are numerical representations of data (text, images, videos, audio, etc.).
 
### [A] Creating tensors
We can create tensors directly by specifying the data in the tensors using the [torch.tensor()](https://pytorch.org/docs/stable/tensors.html) function, or with random numbers in a certain shape using the [torch.rand()](https://pytorch.org/docs/stable/generated/torch.rand.html) function. Other commons ways to create tensors are using the functions
[torch.zeros()](https://pytorch.org/docs/stable/generated/torch.zeros.html),
[torch.ones()](https://pytorch.org/docs/stable/generated/torch.ones.html),
[torch.zeros_like()](https://pytorch.org/docs/stable/generated/torch.zeros_like.html),
[torch.ones_like()](https://pytorch.org/docs/stable/generated/torch.ones_like.html) and
[torch.arange()](https://pytorch.org/docs/stable/generated/torch.arange.html).
 
Apart from the data that is present in the tensors, three other parameters that are important to specify when creating a tensor are: dtype (what data type is the tensor e.g. torch.float16 or torch.float32), device (what device is your tensor on), requires_grad (whether or not to track gradients with the operations on this tensor). We can cast tensors into different data types using tensor_new = tensor_old.type(torch.datatype).
 
We can create a tensor from a numpy array using the [torch.from_numpy(ndarray)](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) function, and create a numpy array from a torch tensor using the [torch.Tensor.numpy()](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) function. Note that the default data type of PyTorch is torch.float32, and that of NumPy is float64.

### [B] Manipulating tensors
We can manipulate tensors by using the following operations: addition, subtraction, element-wise multiplication and element-wise division. These are best done using the python symbols $+$, $-$, $*$ and $/$. When applying these operations on tensors whose shapes do not match, [broadcasting rules](https://pytorch.org/docs/stable/notes/broadcasting.html) will be applied. We can also do a different type of multiplication: matrix multiplication. This can be done using the [torch.matmul()](https://pytorch.org/docs/stable/generated/torch.matmul.html) function or using @ operator. [torch.einsum()](https://pytorch.org/docs/stable/generated/torch.einsum.html) is an excellent function for generic product and sum operations on two tensors along different dimensions. Numerous examples are shown [here](https://rockt.github.io/2018/04/30/einsum), [here](https://ejenner.com/post/einsum/) and [here](https://www.youtube.com/watch?v=pkVwUVEHmfI).

### [C] Manipulating tensor shapes
We can reshape a tensor using the [torch.reshape()](https://pytorch.org/docs/stable/generated/torch.reshape.html) or the [torch.Tensor.view()](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html#torch.Tensor.view) function. We can concatenate a sequence of tensors along an existing dimension using the [torch.cat()](https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat) function and along a new dimension using the [torch.stack()](https://pytorch.org/docs/stable/generated/torch.stack.html) function. We can remove dimensions of size 1 using the [torch.squeeze()](https://pytorch.org/docs/stable/generated/torch.squeeze.html) function, and add dimensions with size 1 using the [torch.unsqueeze()](https://pytorch.org/docs/stable/generated/torch.unsqueeze.html) function. We can rearrange the dimensions of a tensor in a specified order using the [torch.permute()](https://pytorch.org/docs/stable/generated/torch.permute.html) function, or we can swap any two axes of a tensor using the [torch.transpose()](https://pytorch.org/docs/stable/generated/torch.transpose.html#torch.transpose) function. As explained [here](https://stackoverflow.com/questions/48915810/what-does-contiguous-do-in-pytorch), some of these operations do not generate a new tensor with a new layout, but just modify meta information in the Tensor object. But contiguity of storage may be necessary for some downstream functions. We can determine contiguity by [torch.Tensor.is_contiguous()](https://pytorch.org/docs/stable/generated/torch.Tensor.is_contiguous.html#torch.Tensor.is_contiguous) and use [torch.Tensor.contiguous()](https://pytorch.org/docs/stable/generated/torch.Tensor.contiguous.html) to make a copy of the tensor such that the order of its elements in memory is the same as if it had been created from scratch with the same data.

### [D] Aggregating tensors
We can find the minimum, maximum and mean values in a tensor using the [torch.min()](https://pytorch.org/docs/stable/generated/torch.min.html), [torch.max()](https://pytorch.org/docs/stable/generated/torch.max.html) and [torch.mean()](https://pytorch.org/docs/stable/generated/torch.mean.html) functions. We can sum all values in a tensor using the [torch.sum()](https://pytorch.org/docs/stable/generated/torch.sum.html) function. In all these functions, we can also specify the dim along which to apply these operations, and also whether or not we would want the output to preserve the original dimensionality. We can get the indices of the min and max values using the [torch.argmin()](https://pytorch.org/docs/stable/generated/torch.argmin.html) and the [torch.argmax()](https://pytorch.org/docs/stable/generated/torch.argmax.html#torch.argmax) functions.

<br>

## Neural Networks

### [A] Creating models
[Torch.nn](https://pytorch.org/docs/stable/nn.html) contains all of PyTorch's building blocks for neural networks. Almost all neural network models that we will build in PyTorch will inherit from the [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) class. This class contains the basic building blocks that all neural networks will use.

Class constructor: In the init() function of our model class, we will define learnable parameters either directly using the [nn.Parameter](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter) class (Parameters are [torch.Tensor](https://pytorch.org/docs/stable/tensors.html) subclasses that, when used within [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module), are automatically added to the list of its parameters, and will appear e.g. in model.parameters() iterator) or using predefined layers such as [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html), [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d), [non-linear activation layers](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity), etc. [torch.nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential) and [torch.nn.ModuleList](https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList) are two ways of chaining together multiple layers.

Forward method: The model class should also contain a forward() method that defines the computation to be performed at every call. This function takes data as inputs, computes the forward pass of the neural network using the input data and the model parameters and returns the model outputs.

Once the model is created, [model.parameters()](https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.parameters) returns an iterator over all the parameters of the model, and [model.state_dict()](https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.state_dict) returns a dictionary of all parameters of the model and their current values. Once created, we can move our model to a GPU using the [torch.nn.Module.to()](https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.to) function.

We can use [torchinfo](https://github.com/TylerYep/torchinfo) to print summary of the model's architecture.

### [B] Training models
Once built, we now have to train our models. Here, we usually follow the following steps in order. (1) We set our model in training mode via [model.train()](https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.train). This needs to be done because certain layers e.g. batch normalization behave differently at training and test time. (2) We define appropriate loss functions that measure discrepancy between the current and desired outputs of our models. This can be done using [torch.nn loss functions](https://pytorch.org/docs/stable/nn.html#loss-functions), or by writing these functions from scratch. (3) We compute the gradients of the loss function with respect to model parameters. This can be done via the [backward()](https://pytorch.org/docs/stable/generated/torch.autograd.backward.html#torch.autograd.backward) method defined in the torch.[autograd](https://pytorch.org/docs/stable/autograd.html) package. (4) We update the parameters via [optimizer.step()](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html#torch.optim.Optimizer.step) using the [torch.optim](https://pytorch.org/docs/stable/optim.html) package where many commonly used optimizers have been defined. (5) Once the parameters have been updated, we normally set the parameter gradients to zero using the [optimizer.zero_grad()](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html#torch.optim.Optimizer.zero_grad), otherwise the gradient values keep accumulating from previous steps.

### [C] Evaluating models
For evaluating our models, we first set our model in eval mode via [model.eval()](https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval) and then make predictions inside the [torch.inference_model()](https://pytorch.org/docs/stable/generated/torch.autograd.grad_mode.inference_mode.html) [context manager](https://realpython.com/lessons/context-managers-intro/). This disables computation of the gradients, which are only necessary for training. Another way to do this is via the [torch.no_grad()](https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad) context manager. [Here](https://pytorch.org/docs/stable/notes/autograd.html#locally-disable-grad-doc) and [here](https://x.com/PyTorch/status/1437838231505096708?lang=en) are discussions on the pros and cons of using these different ways of preventing gradient computations.

### [D] Saving and loading models
PyTorch has a nice [tutorial](https://pytorch.org/tutorials/beginner/saving_loading_models.html) on saving and loading models. In brief, [torch.save()](https://pytorch.org/docs/stable/generated/torch.save.html) saves a PyTorch object in Python's pickle format. [torch.load()](https://pytorch.org/docs/stable/generated/torch.load.html) loads a saved PyTorch object. [torch.nn.Module.load_state_dict()](https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.load_state_dict) loads a model's saved state dictionary. PyTorch recommends that only state_dicts of the model (and the optimizer) are saved, that is, save via 
torch.save({'model': model.state_dict(), 'optimizer': optimizer.state_dict()}, path) and load via model = ModelClass(); model.load_state_dict(torch.load(path))['model']. Instead of saving and loading the entire model, that is, save via torch.save(model, path) and load via model = torch.load(path) (# Model class must be defined somewhere).

<br>

## Computer Vision
[Torchvision](https://pytorch.org/vision/stable/index.html) is PyTorch's library for CV. [Torchvision.datasets](https://pytorch.org/vision/stable/datasets.html) provides common CV datasets and data loading functions for CV. [Torchvision.transforms](https://pytorch.org/vision/stable/transforms.html) provides functions for manipulating images. [Torch.utils.data](https://pytorch.org/docs/stable/data.html) provides functionality for creating custom datasets and dataloaders. 

<br>

## Custom Datasets
[Torchvision.datasets](https://pytorch.org/vision/stable/datasets.html#base-classes-for-custom-datasets) also provides support for using custom datasets. First, let's talk about some useful Python functions for data preparation. The [requests](https://pypi.org/project/requests/) module (explained [here](https://www.youtube.com/watch?v=Xi1F2ZMAZ7Q)) let's us send https requests over the internet. The [zipfile](https://docs.python.org/3/library/zipfile.html) module (explained [here](https://www.youtube.com/watch?v=z0gguhEmWiY)) allows us to work with zipped datasets. The [pathlib](https://docs.python.org/3/library/pathlib.html) module (explained [here](https://www.youtube.com/watch?v=YwhOUyTxXVE)) provides a [Path](https://docs.python.org/3/library/pathlib.html#pathlib.Path) class. [os.walk()](https://docs.python.org/3/library/os.html#os.walk) helps us walk through a directory. Once we have folders of unzipped images, we need to turn them into tensors using one of the conversion functions [torchvision.transforms.v2.to<>()](https://pytorch.org/vision/stable/transforms.html#conversion-transforms), and then turn those into a [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) and subsequently a [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).

<br>

## Misc
### [A] Reproducibility
We can set the random seed for PyTorch using the [torch.manual_seed()](https://pytorch.org/docs/stable/generated/torch.manual_seed.html) function. Read more about [reproducibility](https://pytorch.org/docs/stable/notes/randomness.html) here.

### [B] Running computations on GPUs
We want to do this because GPUs = faster computations on numbers thanks to CUDA, NVIDIA hardware and PyTorch doing work behind the scenes to leverage these. We can use a free GPU on [Google Colab](https://colab.research.google.com/), or [purchase our own GPU](https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/) or rent one from AWS, Azure, etc. For the latter two options, we need to setup PyTorch and CUDA as discussed [here](https://pytorch.org/get-started/locally/). In code, we can check if GPU is available using [torch.cuda.is_available()](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html) function. If available, we can set device = "cuda". Else we can set device = "cpu". We can get the number of available GPUs using the [torch.cuda.device_count()](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html) function. We can copy a tensor to a device using the [torch.Tensor.to()](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html) function, or directly create a tensor on a device by passing it in the [torch.tensor()](https://pytorch.org/docs/stable/generated/torch.tensor.html) function. We can copy a tensor from a GPU back to a CPU using the [torch.Tensor.cpu()](https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html) function.

<br>

### Further Reading
 - [Speeding up deep learning](https://horace.io/brrr_intro.html)

### References
 - [PyTorch documentation](https://pytorch.org/docs/stable/index.html)
 - [PyTorch cheat sheet](https://pytorch.org/tutorials/beginner/ptcheat.html)
 - [PyTorch discussion forum](https://discuss.pytorch.org/)
 - [PyTorch in a day video tutorial](https://www.youtube.com/watch?v=Z_ikDlimN6A)





